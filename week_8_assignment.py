# -*- coding: utf-8 -*-
"""Week_8_assignment.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zvV5nuDWNFhxSTFExGoevpa-ycV4Fx0t
"""

!pip install -q faiss-cpu sentence-transformers transformers

from google.colab import files
uploaded = files.upload()

import pandas as pd
file_name = list(uploaded.keys())[0]
df = pd.read_csv(file_name)

print("Columns in your dataset:", df.columns.tolist())

docs = df.astype(str).apply(lambda row: ' | '.join(row), axis=1).tolist()

from sentence_transformers import SentenceTransformer
import faiss
import numpy as np

embed_model = SentenceTransformer("all-MiniLM-L6-v2")
doc_embeddings = embed_model.encode(docs, convert_to_numpy=True)

index = faiss.IndexFlatL2(doc_embeddings.shape[1])
index.add(doc_embeddings)

from transformers import pipeline
qa_pipeline = pipeline("text2text-generation", model="google/flan-t5-base")

def rag_chatbot(question, top_k=5):
    q_embed = embed_model.encode([question])
    _, indices = index.search(q_embed, top_k)
    context = "\n".join([docs[i] for i in indices[0]])
    prompt = f"Answer the question based on the context:\n\n{context}\n\nQuestion: {question}"
    result = qa_pipeline(prompt, max_new_tokens=150)
    return result[0]["generated_text"].strip()

while True:
    question = input("\n Ask a question (or type 'exit' to quit): ")
    if question.lower() == "exit":
        print("Chatbot ended.")
        break
    answer = rag_chatbot(question)
    print(" Answer:", answer)

